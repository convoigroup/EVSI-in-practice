colnames(theta)<-c("pi1","rho","gamma","gamma2","lambda.2.3.fix","lambda.1.3.fix","SE1","SE2")
rm(prior.model,extra.lines,l)
## Find the incremental net benefit for each treatment
INB<-NB[,2]-NB[,1]
rm(NB)
rm(m.1.3,m.2.3,mu.amb,mu.chemo,mu.death,mu.e.hosp,mu.hosp,s.amb,s.death,
s.hosp,s.rho,sd.amb,sd.hosp,v.1.3,v.2.3,var.chemo,var.e.amb,var.e.hosp,
betaPar,model,lognPar,sd.death)
#Markov Model for Chronic Pain - Adapted from Sullivan et al.
#Copyright: Anna Heath 2017
#Model has two treatment options for chronic pain and costs and effects are determined using a Markov Model
#Treatment 1: Morphine
#Treatment 2: Novel Treatment
#N: PSA sample size
#NOTE: Throughout the PSA distributions are taken as having the mean given by the parameter estimate and the standard error as 10%
#of the parameter estimate.
#t is treatment and l is the number of treatments that have been attempted
##Packages
library(BCEA)
library(R2OpenBUGS)
library(R2jags)
library(mgcv)
library(psych)
gamma.par<-function(par.est){
alpha=100
beta=100/par.est
scale=par.est/100
return(list(alpha=alpha,beta=beta,scale=scale))
}
beta.par<-function(par.est){
alpha<-(1-par.est)/0.01-par.est
beta<-alpha*(1/par.est-1)
return(list(alpha=alpha,beta=beta))
}
prob.novel<-0.3
cost.novel<-6
N<-100000
#Costs
#Treatment costs are considered known and taken from the literature. The novel treatment is assumed to be
#6 times more expensive than Oxycodone
c.t1<-2.632729166666670000
c.t2<-9.2011500000*cost.novel
#The comedication cost per cycle - this is for complications associated with the pain medication
#Costs based on a previous study so inflation needs to be taken into account
PriceIndex0910<-268.6
PriceIndex1213<-289.1
Inflation<-PriceIndex1213/PriceIndex0910
c.med.t1<-rgamma(N,shape=gamma.par(2.1*Inflation)$alpha,rate=gamma.par(2.1*Inflation)$beta)
#Novel theraphy gives an improvement on Oxycodone so the cost is based on this improvement
c.med.t2<-rgamma(N,shape=gamma.par(0.04*Inflation*(1-prob.novel))$alpha,rate=gamma.par(0.04*Inflation*(1-prob.novel))$beta)
#Costs of adverse events
c.ae<-rgamma(N,shape=gamma.par(6.991009409)$alpha,rate=gamma.par(6.991009409)$beta)
#The cost of withdrawing from the theraphy is the same irrespective of the reason you withdaw
c.withdraw.ae<-rgamma(N,shape=gamma.par(106.911031273)$alpha,rate=gamma.par(106.911031273)$beta)
c.withdraw<-rgamma(N,shape=gamma.par(106.911031273)$alpha,rate=gamma.par(106.911031273)$beta)
#Cost of discontinuing treatment is based on visiting the GP
c.dist<-rgamma(N,shape=gamma.par(18.5)$alpha,rate=gamma.par(18.5)$beta)
#Cost of second round of treatment
c.l2<-9.2011500000+0.04*Inflation
#Cost of third round of treatment
c.l3<-2.632729166666670000+2.1*Inflation
####Utilities###
#No adverse effects for the first treatment
u.l1.noae<-rbeta(N,beta.par(0.695000000)$alpha,beta.par(0.695000000)$beta)
#Adverse effects
u.l1.ae<-rbeta(N,beta.par(0.583000000)$alpha,beta.par(0.583000000)$beta)
#Withdraw from treatment due to adverse effects
u.l1.withdraw.ae<-rbeta(N,beta.par(0.503000000)$alpha,beta.par(0.503000000)$beta)
#Withdraw due to other reasons
u.l1.withdraw.noae<-rbeta(N,beta.par(0.405000000)$alpha,beta.par(0.405000000)$beta)
#Multiplier to give the utilities when on the 2nd treatment options
u.l2<-0.900
#Utility for 3rd case of treatment
u.l3<-(u.l1.noae+u.l1.ae)/2
#Discontinuing treatment
u.dist<-u.l1.withdraw.noae*0.8
####Transition Probabilities####
#For the first round of treatments
#probability of adverse effects
p.ae.l1.t1<-rbeta(N,beta.par(0.436159243)$alpha,beta.par(0.436159243)$beta)
p.ae.l1.t2<-p.ae.l1.t1*(1-prob.novel)
#probility of withdrawal due to adverse effects
p.with.ae.l1.t1<-rbeta(N,beta.par(0.055739588)$alpha,beta.par(0.055739588)$beta)
p.with.ae.l1.t2<-rbeta(N,beta.par(0.022958454)$alpha,beta.par(0.022958454)$beta)
#probability of withdrawal due to other reasons
p.with.l1.t1<-rbeta(N,beta.par(0.012741455)$alpha,beta.par(0.012741455)$beta)
p.with.l1.t2<-rbeta(N,beta.par(0.001612408)$alpha,beta.par(0.001612408)$beta)
#probability of discontinuation
p.dist.l1<-rbeta(N,beta.par(0.050000000)$alpha,beta.par(0.050000000)$beta)
#For the second round of treatment that only has one treatment
#probability of adverse effects
p.ae.l2.t1<-rbeta(N,beta.par(0.463500000)$alpha,beta.par(0.463500000)$beta)
p.ae.l2.t2<-rbeta(N,beta.par(0.463500000)$alpha,beta.par(0.463500000)$beta)
#probility of withdrawal due to adverse effects
p.with.ae.l2.t1<-rbeta(N,beta.par(0.032797792)$alpha,beta.par(0.032797792)$beta)
p.with.ae.l2.t2<-rbeta(N,beta.par(0.032797792)$alpha,beta.par(0.032797792)$beta)
#probability of withdrawal due to other reasons
p.with.l2.t1<-rbeta(N,beta.par(0.002303439)$alpha,beta.par(0.002303439)$beta)
p.with.l2.t2<-p.with.l2.t1#rbeta(N,beta.par(0.002303439)$alpha,beta.par(0.002303439)$beta)
#probability of discontinuation
p.dist.l2<-rbeta(N,beta.par(0.100000000)$alpha,beta.par(0.100000000)$beta)
###Transition Matrices###
#First line of treatment l1
#For treatment 1 t1
No.AE.l1.t1<-cbind((1-p.with.ae.l1.t1-p.with.l1.t1)*(1-p.ae.l1.t1),
(1-p.with.ae.l1.t1-p.with.l1.t1)*(p.ae.l1.t1),
p.with.ae.l1.t1,
p.with.l1.t1,
rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N))
AE.l1.t1<-cbind((1-p.with.ae.l1.t1-p.with.l1.t1)*(1-p.ae.l1.t1),
(1-p.with.ae.l1.t1-p.with.l1.t1)*(p.ae.l1.t1),
p.with.ae.l1.t1,
p.with.l1.t1,
rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N))
With.AE.l1.t1<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.dist.l1)*(1-p.ae.l2.t1),
(1-p.dist.l1)*(p.ae.l2.t1),
rep(0,N),rep(0,N),rep(0,N),
p.dist.l1)
With.l1.t1<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.dist.l1)*(1-p.ae.l2.t1),
(1-p.dist.l1)*(p.ae.l2.t1),
rep(0,N),rep(0,N),rep(0,N),
p.dist.l1)
#Second line of treatment l2
No.AE.l2.t1<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.with.ae.l2.t1-p.with.l2.t1)*(1-p.ae.l2.t1),
(1-p.with.ae.l2.t1-p.with.l2.t1)*(p.ae.l2.t1),
p.with.ae.l2.t1,p.with.l2.t1,rep(0,N),rep(0,N))
AE.l2.t1<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.with.ae.l2.t1-p.with.l2.t1)*(1-p.ae.l2.t1),
(1-p.with.ae.l2.t1-p.with.l2.t1)*(p.ae.l2.t1),
p.with.ae.l2.t1,p.with.l2.t1,rep(0,N),rep(0,N))
#First line of treatment l1
#For treatment 2 t2
No.AE.l1.t2<-cbind((1-p.with.ae.l1.t2-p.with.l1.t2)*(1-p.ae.l1.t2),
(1-p.with.ae.l1.t2-p.with.l1.t2)*(p.ae.l1.t2),
p.with.ae.l1.t2,
p.with.l1.t2,rep(0,N),rep(0,N),rep(0,N),rep(0,N),
rep(0,N),rep(0,N))
AE.l1.t2<-cbind((1-p.with.ae.l1.t2-p.with.l1.t2)*(1-p.ae.l1.t2),
(1-p.with.ae.l1.t2-p.with.l1.t2)*(p.ae.l1.t2),
p.with.ae.l1.t2,
p.with.l1.t2,rep(0,N),rep(0,N),rep(0,N),rep(0,N),
rep(0,N),rep(0,N))
With.AE.l1.t2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.dist.l1)*(1-p.ae.l2.t2),
(1-p.dist.l1)*(p.ae.l2.t2),
rep(0,N),rep(0,N),rep(0,N),
p.dist.l1)
With.l1.t2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.dist.l1)*(1-p.ae.l2.t2),
(1-p.dist.l1)*(p.ae.l2.t2),
rep(0,N),rep(0,N),rep(0,N),
p.dist.l1)
#Second line of treatment l2
No.AE.l2.t2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.with.ae.l2.t2-p.with.l2.t2)*(1-p.ae.l2.t2),
(1-p.with.ae.l2.t2-p.with.l2.t2)*(p.ae.l2.t2),
p.with.ae.l2.t2,p.with.l2.t2,rep(0,N),rep(0,N))
AE.l2.t2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),
(1-p.with.ae.l2.t2-p.with.l2.t2)*(1-p.ae.l2.t2),
(1-p.with.ae.l2.t2-p.with.l2.t2)*(p.ae.l2.t2),
p.with.ae.l2.t2,p.with.l2.t2,rep(0,N),rep(0,N))
With.AE.l2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(1,N))
#1-p.dist.l2,p.dist.l2)
With.l2<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(1,N))
#1-p.dist.l2,p.dist.l2)
##Absorbing states
Subs.treat<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(1,N),rep(0,N))
Dist<-cbind(rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(0,N),rep(1,N))
PSA.Trans.Mat.t1<-array(NA,dim=c(10,10,N))
PSA.Trans.Mat.t1[1,,]<-(t(No.AE.l1.t1))
PSA.Trans.Mat.t1[2,,]<-(t(AE.l1.t1))
PSA.Trans.Mat.t1[3,,]<-(t(With.AE.l1.t1))
PSA.Trans.Mat.t1[4,,]<-(t(With.l1.t1))
PSA.Trans.Mat.t1[5,,]<-(t(No.AE.l2.t1))
PSA.Trans.Mat.t1[6,,]<-(t(AE.l2.t1))
PSA.Trans.Mat.t1[7,,]<-(t(With.AE.l2))
PSA.Trans.Mat.t1[8,,]<-(t(With.l2))
PSA.Trans.Mat.t1[9,,]<-(t(Subs.treat))
PSA.Trans.Mat.t1[10,,]<-(t(Dist))
PSA.Trans.Mat.t2<-PSA.Trans.Mat.t1
PSA.Trans.Mat.t2[1,,]<-(t(No.AE.l1.t2))
PSA.Trans.Mat.t2[2,,]<-(t(AE.l1.t2))
PSA.Trans.Mat.t2[3,,]<-(t(With.AE.l1.t2))
PSA.Trans.Mat.t2[4,,]<-(t(With.l1.t2))
PSA.Trans.Mat.t2[5,,]<-(t(No.AE.l2.t2))
PSA.Trans.Mat.t2[6,,]<-(t(AE.l2.t2))
c.Mat.t1<-cbind(c.t1+c.med.t1,
c.t1+c.med.t1+c.ae,
c.withdraw.ae,
c.withdraw,
c.l2,
c.l2+c.ae,
c.withdraw.ae,
c.withdraw,
c.l3,
c.dist)
c.Mat.t2<-cbind(c.t2+c.med.t2,
c.t2+c.med.t2+c.ae,
c.withdraw.ae,
c.withdraw,
c.l2,
c.l2+c.ae,
c.withdraw.ae,
c.withdraw,
c.l3,
c.dist)
u.Mat<-cbind(u.l1.noae,
u.l1.ae,
u.l1.withdraw.ae,
u.l1.withdraw.noae,
u.l1.noae*u.l2,
u.l1.ae*u.l2,
u.l1.withdraw.ae*u.l2,
u.l1.withdraw.noae*u.l2,
u.l3,
u.dist)*7/365.25
Time_Horizen<-52
InitVector<-c(1,0,0,0,0,0,0,0,0,0)
###Markov Model####
Markov_Prob <- function(TransArray){
trace_matrix <- matrix(NA, nrow=Time_Horizen, ncol=ncol(TransArray))
trace_matrix[1,] <- InitVector
trace_matrix[2,] <- InitVector %*% TransArray
for (i in 3:nrow(trace_matrix)){
trace_matrix[i,] <- trace_matrix[i-1,] %*% TransArray
}
#hcc = half cycle corrected
hcc_trace_matrix <- matrix(NA, nrow=Time_Horizen, ncol=ncol(TransArray))
hcc_trace_matrix[1,] <- 0.5*InitVector + 0.5*trace_matrix[2,]
for (i in 2:Time_Horizen-1){
hcc_trace_matrix[i,] <- 0.5*trace_matrix[i,] + 0.5*trace_matrix[i+1,]
}
hcc_trace_matrix[Time_Horizen,] <- trace_matrix[Time_Horizen,]
return(hcc_trace_matrix)
}
Prob.Array.1<-array(NA,c(52,10,N))
for(i in 1:N){
Prob.Array.1[,,i]<-Markov_Prob(PSA.Trans.Mat.t1[,,i])}
Prob.Array.2<-array(NA,c(52,10,N))
for(i in 1:N){
Prob.Array.2[,,i]<-Markov_Prob(PSA.Trans.Mat.t2[,,i])}
costs.t1<-array(NA,N)
for(i in 1:N){
costs.t1[i]<-  sum(Prob.Array.1[,,i]%*%c.Mat.t1[i,])}
costs.t2<-array(NA,N)
for(i in 1:N){
costs.t2[i]<- sum(Prob.Array.2[,,i]%*%c.Mat.t2[i,])
}
effects.t1<-array(NA,N)
for(i in 1:N){
effects.t1[i]<-  sum(Prob.Array.1[,,i]%*%u.Mat[i,])}
effects.t2<-array(NA,N)
for(i in 1:N){
effects.t2[i]<- sum(Prob.Array.2[,,i]%*%u.Mat[i,])
}
####EVPPI####
#This gives the standard cost-effectiveness analysis for the Chronic Pain model.
#It also has the EVPPI calculations to determine where to focus analysis.
discount.15<-sum(1/(1+0.035)^(0:15))
m<-bcea(discount.15*cbind(effects.t1,effects.t2),discount.15*cbind(costs.t1,costs.t2),ref=2,wtp=c(0,20000))
var.pr<-var(m$ib[which(m$k==20000),])
pars<-cbind(c.ae,c.dist,c.med.t1,c.med.t2,c.withdraw,c.withdraw.ae,p.ae.l1.t1,p.ae.l1.t2,p.dist.l1,
p.dist.l2,p.with.ae.l1.t1,p.with.ae.l1.t2,p.with.l1.t1,p.with.l1.t2,p.ae.l2.t1,
p.ae.l2.t2,p.with.ae.l2.t1,p.with.ae.l2.t2,p.with.l2.t1,p.with.l2.t2,
u.dist,u.l1.ae,u.l1.noae,u.l1.withdraw.ae,u.l1.withdraw.noae,u.l3)
#Utility
system.time(save.full<-evppi(c("u.l1.noae","u.l1.withdraw.noae"),pars,m,method="gam"))
save<-20000*save.full$fitted.effects-save.full$fitted.costs
save<-save[,1]
betaPar <- function(m,s){
a <- m*( (m*(1-m)/s^2) -1 )
b <- (1-m)*( (m*(1-m)/s^2) -1 )
list(a=a,b=b)
}
####GAM Fitting - STRONG et al method####
EVSI.gam<-array()
var.fit<-array()
sig.X.noae<-0.300
sig.X.with<-0.310
n.<-c(10,25,50,100,150)
N<-100000
start<-Sys.time()
for(i in 1:5){
n.loop<-n.[i]
X.gam<-array(NA,dim=c(N,2))
X.gam.with<-array(NA,dim=c(N,2))
for(j in 1:N){
rand<-rbinom(n.loop,1,0.687)
samp<-rbeta(sum(rand),betaPar(u.l1.noae[j],sig.X.noae)$a,betaPar(u.l1.noae[j],sig.X.noae)$b)
samp.with<-rbeta(sum(rand),betaPar(u.l1.withdraw.noae[j],sig.X.with)$a,betaPar(u.l1.withdraw.noae[j],sig.X.with)$b)
X.gam[j,]<-c(psych::geometric.mean(samp),psych::geometric.mean(1-samp))
X.gam.with[j,]<-c(psych::geometric.mean(samp.with),psych::geometric.mean(1-samp.with))
}
gam.fit<-gam(m$ib[which(m$k==20000),1:N]~te(X.gam[,1], X.gam[,2], X.gam.with[,1], X.gam.with[,2]))
# gam(m$ib[which(m$k==20000),1:N]~te(X.gam,X.gam.with))
EVSI.gam[i]<-mean(pmax(0,gam.fit$fitted))-max(0,mean(gam.fit$fitted))
var.fit[i]<-var(gam.fit$fitted)}
end<-Sys.time()
end-start
warnings()
EVSI.gam
gam.fit
.096*60
(end-start)*200*2
(end-start)*200*2/60
5*200*2/60
HeathChronic<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIHeathChronic.txt", sep="")
HeathChronicMean<-apply(HeathChronic,2,mean)
HeathChronicSD<-apply(HeathChronic,2,sd)
cbind((apply(HeathChronic,2,mean)-2*apply(HeathChronic,2,sd)),c(450,643,737,803,835),
(apply(HeathChronic,2,mean)+2*apply(HeathChronic,2,sd)))
TRUE;TRUE;TRUE;TRUE;TRUE
JalalChronic<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIJalalChronic.txt", sep="")
JalalChronicMean<-apply(JalalChronic,2,mean)
JalalChronicSD<-apply(JalalChronic,2,sd)
cbind((apply(JalalChronic,2,mean)-2*apply(JalalChronic,2,sd)),c(450,643,737,803,835),
(apply(JalalChronic,2,mean)+2*apply(JalalChronic,2,sd)))
TRUE;FALSE L;FALSE L;FALSE L;FALSE L
MenziesChronic0<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies1.txt", sep="")
MenziesChronic1<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_1.txt", sep="")
MenziesChronic2<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_2_old.txt", sep="")
MenziesChronic3<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_3.txt", sep="")
MenziesChronic4<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_4.txt", sep="")
MenziesChronic5<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_5.txt", sep="")
MenziesChronic6<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIMenzies_2.txt", sep="")
MenziesChronic<-rbind(MenziesChronic0,MenziesChronic1,MenziesChronic2,MenziesChronic3,
MenziesChronic4,MenziesChronic5,MenziesChronic6)
set.seed(12)
MenziesChronic<-MenziesChronic[sample(1:dim(MenziesChronic)[1],200,replace=FALSE),]
MenziesChronicMean<-apply(MenziesChronic,2,mean)
MenziesChronicSD<-apply(MenziesChronic,2,sd)
cbind((apply(MenziesChronic,2,mean)-2*apply(MenziesChronic,2,sd)),c(450,643,737,803,835),
(apply(MenziesChronic,2,mean)+2*apply(MenziesChronic,2,sd)))
TRUE;TRUE;TRUE;TRUE;TRUE
StrongChronic<- read.csv("C:/Users/anna heath/OneDrive/OneDrive - SickKids/EVSI Methods/EVSIStrongChronic.txt", sep="")
StrongChronicMean<-apply(StrongChronic,2,mean)
StrongChronicSD<-apply(StrongChronic,2,sd)
cbind((apply(StrongChronic,2,mean)-2*apply(StrongChronic,2,sd)),c(450,643,737,803,835),
(apply(StrongChronic,2,mean)+2*apply(StrongChronic,2,sd)))
FALSE H;FALSE H;FALSE H;FALSE H;FALSE H;
bottom<-min(c(apply(HeathChronic,2,quantile,probs=c(0.025,0.975)),
apply(JalalChronic,2,quantile,probs=c(0.025,0.975)),
apply(MenziesChronic,2,quantile,probs=c(0.025,0.975)),
apply(StrongChronic,2,quantile,probs=c(0.025,0.975))))
top<-max(c(apply(HeathChronic,2,quantile,probs=c(0.025,0.975)),
apply(JalalChronic,2,quantile,probs=c(0.025,0.975)),
apply(MenziesChronic,2,quantile,probs=c(0.025,0.975)),
apply(StrongChronic,2,quantile,probs=c(0.025,0.975))))
par(mar=c(4,4,1,1)+0.1)
plot(1,1,col="white",yaxt="n",ylab="",xlab="EVSI",lwd=2,pch=4,xlim=c(bottom,top),ylim=c(0.5,5.5))
TRUTH<-c(450,643,737,803,835)
for(i in 0:4){
points(rep(TRUTH[i+1],2),c(0.55,1.4)+i,type="l",lwd=2)
}
library(colorspace)
cols=rainbow_hcl(4)
inits<-seq(0.6,4.6, by=1)
for(i in 1:5){
points(c(HeathChronicMean[i]),rep(inits[i],1),pch=1,lwd=2,col=cols[1])
points(apply(HeathChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i],2),type="l",lwd=2,col=cols[1])
}
for(i in 1:5){
points(c(JalalChronicMean[i]),rep(inits[i]+0.25,1),pch=2,lwd=2,col=cols[2])
points(apply(JalalChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.25,2),type="l",lwd=2,col=cols[2])
}
for(i in 1:5){
points(c(MenziesChronicMean[i]),rep(inits[i]+0.5,1),pch=3,lwd=2,col=cols[3])
points(apply(MenziesChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.5,2),type="l",lwd=2,col=cols[3])
}
for(i in 1:5){
points(c(StrongChronicMean[i]),rep(inits[i]+0.75,1),pch=4,lwd=2,col=cols[4])
points(apply(StrongChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.75,2),type="l",lwd=2,col=cols[4])
}
space<-c(0,0.25,0.5,0.75)
n<-c(10,25,50,100,150)
for(i in 1:5){
axis(2,inits[i]+mean(space),labels=paste("N=",n[i]))}
legend("bottomright",c("MC","Hea","Jal","Men","Str"),pch=c(NA,1:4),lwd=2,col=c("black",cols))
mean(pmax(save,0)-max(0,mean(save))
mean(pmax(save,0))-max(0,mean(save))
mean(pmax(save,0))-max(0,mean(save))
abline(h=mean(pmax(save,0))-max(0,mean(save)))
abline(v=mean(pmax(save,0))-max(0,mean(save)))
top<-max(c(apply(HeathChronic,2,quantile,probs=c(0.025,0.975)),
apply(JalalChronic,2,quantile,probs=c(0.025,0.975)),
apply(MenziesChronic,2,quantile,probs=c(0.025,0.975)),
apply(StrongChronic,2,quantile,probs=c(0.025,0.975)),mean(pmax(save,0))-max(0,mean(save))))
par(mar=c(4,4,1,1)+0.1)
plot(1,1,col="white",yaxt="n",ylab="",xlab="EVSI",lwd=2,pch=4,xlim=c(bottom,top),ylim=c(0.5,5.5))
TRUTH<-c(450,643,737,803,835)
for(i in 0:4){
points(rep(TRUTH[i+1],2),c(0.55,1.4)+i,type="l",lwd=2)
}
library(colorspace)
cols=rainbow_hcl(4)
inits<-seq(0.6,4.6, by=1)
for(i in 1:5){
points(c(HeathChronicMean[i]),rep(inits[i],1),pch=1,lwd=2,col=cols[1])
points(apply(HeathChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i],2),type="l",lwd=2,col=cols[1])
}
for(i in 1:5){
points(c(JalalChronicMean[i]),rep(inits[i]+0.25,1),pch=2,lwd=2,col=cols[2])
points(apply(JalalChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.25,2),type="l",lwd=2,col=cols[2])
}
for(i in 1:5){
points(c(MenziesChronicMean[i]),rep(inits[i]+0.5,1),pch=3,lwd=2,col=cols[3])
points(apply(MenziesChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.5,2),type="l",lwd=2,col=cols[3])
}
for(i in 1:5){
points(c(StrongChronicMean[i]),rep(inits[i]+0.75,1),pch=4,lwd=2,col=cols[4])
points(apply(StrongChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.75,2),type="l",lwd=2,col=cols[4])
}
space<-c(0,0.25,0.5,0.75)
n<-c(10,25,50,100,150)
for(i in 1:5){
axis(2,inits[i]+mean(space),labels=paste("N=",n[i]))}
legend("bottomright",c("MC","Hea","Jal","Men","Str"),pch=c(NA,1:4),lwd=2,col=c("black",cols))
abline(v=mean(pmax(save,0))-max(0,mean(save)))
legend("topleft",c("MC","Hea","Jal","Men","Str"),pch=c(NA,1:4),lwd=2,col=c("black",cols))
legend("topleft",c("MC","Hea","Jal","Men","Str"),pch=c(NA,1:4),lwd=2,col=c("black",cols))
abline(v=mean(pmax(save,0))-max(0,mean(save)),lty=2,lwd=2)
legend("topleft",c("EVPPI","MC","Hea","Jal","Men","Str"),pch=c(NA,NA,4,3,2,1),lwd=2,
col=c("black","black",cols[4],cols[3],cols[2],cols[1]),
lty=c(2,rep(1,5)))
abline(v=mean(pmax(save,0))-max(0,mean(save)),lty=2,lwd=2)
bottom<-min(c(apply(HeathChronic,2,quantile,probs=c(0.025,0.975)),
apply(JalalChronic,2,quantile,probs=c(0.025,0.975)),
apply(MenziesChronic,2,quantile,probs=c(0.025,0.975)),
apply(StrongChronic,2,quantile,probs=c(0.025,0.975))))
top<-max(c(apply(HeathChronic,2,quantile,probs=c(0.025,0.975)),
apply(JalalChronic,2,quantile,probs=c(0.025,0.975)),
apply(MenziesChronic,2,quantile,probs=c(0.025,0.975)),
apply(StrongChronic,2,quantile,probs=c(0.025,0.975)),mean(pmax(save,0))-max(0,mean(save))))
par(mar=c(4,4,1,1)+0.1)
plot(1,1,col="white",yaxt="n",ylab="",xlab="EVSI",lwd=2,pch=4,xlim=c(bottom,top),ylim=c(0.5,5.5))
TRUTH<-c(450,643,737,803,835)
for(i in 0:4){
points(rep(TRUTH[i+1],2),c(0.55,1.4)+i,type="l",lwd=2)
}
library(colorspace)
cols=rainbow_hcl(4)
inits<-seq(0.6,4.6, by=1)
for(i in 1:5){
points(c(HeathChronicMean[i]),rep(inits[i],1),pch=1,lwd=2,col=cols[1])
points(apply(HeathChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i],2),type="l",lwd=2,col=cols[1])
}
for(i in 1:5){
points(c(JalalChronicMean[i]),rep(inits[i]+0.25,1),pch=2,lwd=2,col=cols[2])
points(apply(JalalChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.25,2),type="l",lwd=2,col=cols[2])
}
for(i in 1:5){
points(c(MenziesChronicMean[i]),rep(inits[i]+0.5,1),pch=3,lwd=2,col=cols[3])
points(apply(MenziesChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.5,2),type="l",lwd=2,col=cols[3])
}
for(i in 1:5){
points(c(StrongChronicMean[i]),rep(inits[i]+0.75,1),pch=4,lwd=2,col=cols[4])
points(apply(StrongChronic,2,quantile,probs=c(0.025,0.975))[,i],rep(inits[i]+0.75,2),type="l",lwd=2,col=cols[4])
}
space<-c(0,0.25,0.5,0.75)
n<-c(10,25,50,100,150)
for(i in 1:5){
axis(2,inits[i]+mean(space),labels=paste("N=",n[i]))}
legend("topleft",c("EVPPI","MC","Hea","Jal","Men","Str"),pch=c(NA,NA,4,3,2,1),lwd=2,
col=c("black","black",cols[4],cols[3],cols[2],cols[1]),
lty=c(2,rep(1,5)))
abline(v=mean(pmax(save,0))-max(0,mean(save)),lty=2,lwd=2)
#Required packages
library(earth)
library(R2jags)
library(R2OpenBUGS)
library(BCEA)
library(mgcv)
# Performs the baseline cost-effectiveness analysis
# Estimates EVPPI using the Heath et al method - object names evppi.half
#Set Working Directory to Source File Location
source("Chemotherapy Model.R")
setwd("~/GitHub/EVSI_Comparison/Chemotherapy")
#Required packages
library(earth)
library(R2jags)
library(R2OpenBUGS)
library(BCEA)
library(mgcv)
# Performs the baseline cost-effectiveness analysis
# Estimates EVPPI using the Heath et al method - object names evppi.half
#Set Working Directory to Source File Location
source("Chemotherapy Model.R")
# Performs the baseline cost-effectiveness analysis for a specified willingness to pay.
wtp<-30000
NB<-e*wtp-c
# Matrix of parameters of interest from baseline model.
extra.lines<-(Size.Prior+1):dim(prior.model$BUGSoutput$sims.matrix)[1]
theta<-as.data.frame(prior.model$BUGSoutput$sims.matrix[-extra.lines,c("pi1","rho","gamma","gamma2","lambda.2.3.fix","lambda.1.3.fix","SE[1]","SE[2]")])
colnames(theta)<-c("pi1","rho","gamma","gamma2","lambda.2.3.fix","lambda.1.3.fix","SE1","SE2")
## Number of simulations
n.sim        <- nrow(NB)
## Number of strategies
n.strategies <- ncol(NB)
## Find the incremental net benefit for each treatment
d.star<-which.max(apply(NB,2,mean))
INB<-NB-NB[,d.star]
### EVPI
evpi <- mean(apply(INB,1,max))
evpi
### EVPPI estimation
y<-INB[,-d.star]
lmm1<-gam(y~s(pi1)+s(rho)+s(gamma)+s(gamma2)+s(lambda.2.3.fix)+s(lambda.1.3.fix)+s(SE1)+s(SE2),data=theta)
evppi <- mean(pmax(0,lmm1$fitted.values))
evppi
